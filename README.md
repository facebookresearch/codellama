Code Llama ü¶ô
=============

Code Llama is an advanced family of large language models for code, based on [Llama 2](https://github.com/facebookresearch/llama). It delivers state-of-the-art performance among open models, with infilling capabilities, large input contexts support, and zero-shot instruction following ability for programming tasks. We offer various flavors to cater to a wide range of applications:

*   **Foundation Models (Code Llama)**
*   **Python Specializations (Code Llama - Python)**
*   **Instruction-Following Models (Code Llama - Instruct)**

These models come in 7B, 13B, and 34B parameter sizes, trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. For detailed insights, explore our [research paper](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/).

üì• Download
-----------

To download the model weights and tokenizers, visit the [Meta website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/) and accept our License. After approval, follow the instructions provided via email to start the download.

### Model Sizes

| Model | Size |
| --- | --- |
| 7B | ~12.55GB |
| 13B | 24GB |
| 34B | 63GB |

üîß Setup
--------

Ensure a conda environment with PyTorch / CUDA is available. Clone the repo and install dependencies:

Copy code

`pip install -e .`

ü§ñ Inference
------------

Different models require varying model-parallel (MP) values:

| Model | MP |
| --- | --- |
| 7B | 1 |
| 13B | 2 |
| 34B | 4 |

### Usage

See `example_completion.py` and `example_infilling.py` for usage examples.

### Fine-tuned Instruction Models

Fine-tuned instruction-following models include `CodeLlama-7b-Instruct`, `CodeLlama-13b-Instruct`, `CodeLlama-34b-Instruct`. Use these models for tasks requiring specific formatting and instructions.

üìö Responsible Use
------------------

Please refer to our [Responsible Use Guide](https://github.com/facebookresearch/llama/blob/main/Responsible-Use-Guide.pdf) for details on ethical and safe usage.

üêû Issues
---------

Report bugs, security concerns, or risky content generated by the model:

*   Model issues: [github.com/facebookresearch/codellama](http://github.com/facebookresearch/codellama)
*   Risky content feedback: [developers.facebook.com/llama\_output\_feedback](http://developers.facebook.com/llama_output_feedback)
*   Bugs and security: [facebook.com/whitehat/info](http://facebook.com/whitehat/info)

üìÉ License
----------

Our models are open for both research and commercial use. Review the [LICENSE](https://github.com/facebookresearch/llama/blob/main/LICENSE) and [Acceptable Use Policy](https://github.com/facebookresearch/llama/blob/main/USE_POLICY.md).

üìö References
-------------

1.  [Code Llama Research Paper](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/)
2.  [Code Llama Blog Post](https://ai.meta.com/blog/code-llama-large-language-model-coding/)
